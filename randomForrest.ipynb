{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime: Explaining predictions \n",
    "\n",
    "### What is it ?\n",
    "\n",
    "Local Interpretable Model-Agnostic Explanations (LIME) is a technique for explaining the decisions made by a machine learning model. The designers of LIME state a goal of identifying an interpretable model over the interpretable representation that is locally faithful to the classifier. The authors define their concept of interpretable representations as human understandable analogs for features used in real world models. With the LIME algorithm the authors hope to “explain the predictions of any classifier or regressor in a faithful way, by approximating it locally with an interpretable model”.  This means that using LIME a simple model that is easy to understand is used to explain the predictions of a more complex model in a localized region. \n",
    "\n",
    "## How to use lime \n",
    "\n",
    "### Instalation \n",
    "\n",
    "LIME is disttributed as a pyhton package instalable with pip or can be downloaded directly from the projects [repository](https://github.com/marcotcr/lime) current versions of the library only support python 3 \n",
    "\n",
    "~~~ bash\n",
    "pip install lime \n",
    "~~~\n",
    "\n",
    "### Basic Usage \n",
    "\n",
    "LIME has methods for explaining many different types of Model for this basic tutorial we will use the tool to explain the predictions of a random forest classifier. first we have to import LIME in the normal way \n",
    "\n",
    "~~~ python\n",
    "import lime \n",
    "\n",
    "~~~\n",
    "\n",
    "The first step in using LIME is initialising the LimeTextExplainer class with the class_names variable for the different classes the explainer will be identifying. LIME has many explainer methods that can be used to explain different models \n",
    "\n",
    "\n",
    "~~~ python \n",
    "lime_explainer = lime_text.LimeTextExplainer(class_names=[\"positive\",\"negative\"])\n",
    "~~~\n",
    "\n",
    "Once the Explainer is intialized it can be used to explain a prediction made by a model. For some models the data is pre-processed into vectorized sets (this is the case for some sklearn models) in these cases we may need to set up a pipline to get access to the unprocessed text data. The max number of features also needs to be apllied to the explainer.\n",
    "\n",
    "\n",
    "~~~ python \n",
    "x = 42 # row of data to be classified and explained \n",
    "explaination = explainer.explain_instance(data[x], classfier, num_features=6)\n",
    "~~~\n",
    "\n",
    "The `explaination` object returned by `explain_instance` contains a linnear aproximation of the classifier for the provided data row. This can be used in a number of ways to comunicate the explaination to the user \n",
    "\n",
    "\n",
    "### Types of Explainer\n",
    "\n",
    "As mentioned above there are several different LIME explainer classes used for different types of data. We have already seen `lime_text` , but the class also includes `lime_tabular` and `lime_images` for tabular and image data respectivly. \n",
    "\n",
    "\n",
    "###  `lime_images`\n",
    "\n",
    "We can seperatly import the diferent lime components using the `from` import pattern. Here we import the lime images component.We will use an example from the lime documentation.\n",
    "\n",
    "~~~ python \n",
    "from lime import lime_image\n",
    "~~~\n",
    "\n",
    "For the image explainer it is not nessasary to initialize the explainer with lables like the text explainer \n",
    "\n",
    "~~~ python \n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "~~~\n",
    "\n",
    "Building an explaination for an image instance requires different parameters than the explainer for text models.\n",
    "This example taken from the LIME documentation is explaining a model which idetifies cats and dogs in an image.\n",
    "we can see that for this explainer we need to pass the image and the model in addition to the `top_labels` parameter which controls the number of labels the explainer will return. `hide_color` which is the colour for a super pixel to be disabled, this value can also be `None`. `num_samples` is the size of the neighborhood to learn the linear model.\n",
    "\n",
    "~~~ python \n",
    "explanation = explainer.explain_instance(image, predict_fn, top_labels=5, hide_color=0, num_samples=1000)\n",
    "~~~\n",
    "\n",
    "Like the explain instance for `lime_text` this instance contains a linear model of the local being explained. However, the explaination produced has different methods for displaying the explaination includig mathods for masking and superimposing colour over the classified image. \n",
    "\n",
    "\n",
    "###  `lime_tabular`\n",
    "\n",
    "The `lime_tabular` explainer is used to explain predictions on matrix data. This explainer differs from the `lime_text` and `lime_images` explainers in that it requires a training set in order to instantiate the explainer. we will use an example from the LIME documentation to demonstarte this class. \n",
    "first we import the class in the usual way.\n",
    "\n",
    "~~~ python \n",
    "from lime import lime_tabular\n",
    "~~~\n",
    "\n",
    "Then we instatniate the explainer \n",
    "\n",
    "~~~ python\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train, feature_names=feature_names, class_names=target_names, discretize_continuous=True)\n",
    "~~~\n",
    "\n",
    "\n",
    "finally we create the explaination \n",
    "\n",
    "~~~ python \n",
    "explaination = explainer.explain_instance(test[x], model, num_features=2, top_labels=1)\n",
    "~~~\n",
    "### Explaining Instances \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http response: 200 OK\n",
      "\n",
      "\n",
      "[[164  35]\n",
      " [ 37 164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82       199\n",
      "    positive       0.82      0.82      0.82       201\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n",
      "\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "import tarfile\n",
    "import os \n",
    "import gensim\n",
    "import gensim.downloader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "url = \"https://www.cs.jhu.edu/~mdredze/datasets/sentiment/processed_acl.tar.gz\"\n",
    "filename = \"processed_acl\"\n",
    "extension = \".tar.gz\"\n",
    "\n",
    "response = requests.get(url, allow_redirects=True)\n",
    "\n",
    "print(\"http response:\",response.status_code,response.reason)\n",
    "\n",
    "with open(filename+extension,\"wb\") as file: \n",
    "    file.write(response.content)\n",
    "    \n",
    "tar = tarfile.open(filename+extension, \"r:gz\")\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "# # merge files using shell commands \n",
    "print(os.popen(\"cat \" + filename+\"/books/negative.review > mixed.txt\").read())\n",
    "print(os.popen(\"cat \" + filename+\"/books/positive.review >> mixed.txt\").read())\n",
    "# print(os.popen(\"cat \" + filename+\"/dvd/all.review >> mixed.txt\").read())\n",
    "# print(os.popen(\"cat \" + filename+\"/dvd/positive.review >> mixed.txt\").read())\n",
    "\n",
    "\n",
    "\n",
    "# parse data into array for word 2 vect \n",
    "dataArray = []\n",
    "labelArray = []\n",
    "\n",
    "with open(\"mixed.txt\", \"r\") as datafile: \n",
    "    lines = datafile.readlines()\n",
    "    for e in lines:\n",
    "        lineList= []\n",
    "        splitLine = e.split()\n",
    "        label = splitLine.pop(-1)\n",
    "        for i in splitLine:\n",
    "            dictSplit = i.split(':')\n",
    "            lineList.append(dictSplit[0])\n",
    "        dataArray.insert(-1, lineList)\n",
    "        labelArray.insert(-1, (label.split(':')[1]))\n",
    "\n",
    "#download word2vec model          \n",
    "word2vec = gensim.downloader.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "\n",
    "# create mean embedding \n",
    "embed = np.array([ np.mean([word2vec[w] for w in words if w in word2vec], axis=0) for words in dataArray])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embed, labelArray, test_size=0.2, random_state=42)\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=700, random_state=42)\n",
    "text_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dl tubspam data set \n",
    "# load into numpy array \n",
    "# create embedings on full text \n",
    "# use classifier to classify the dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lime explainer "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
